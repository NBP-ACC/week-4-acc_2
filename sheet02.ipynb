{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Osnabrück University - A\u0026C: Computational Cognition (Summer Term 2019)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Exercise Sheet 02: Basic statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This week\u0027s sheet should be solved and handed in at 14:00 at **Tuesday, April 30, 2019**. If you need help (and Google and other resources were not enough), feel free to contact your tutors. Please push your results to your Github group folder.\n",
        "\n",
        "In this exercise sheet you will have to work with ```pandas``` and ```seaborn```. ```pandas``` is one of the most preferred and widely used tools in data processing. What’s cool about ```pandas``` is that it takes data (like a CSV or TSV file, or a SQL database) and creates a Python object with rows and columns called \u0027data frame\u0027 that looks very similar to tables in a statistical software (think Excel or SPSS for example). ```pandas``` makes data processing a lot easier in comparison to working with lists and/or dictionaries through for-loops or list comprehension.  \n",
        "```seaborn``` is a library for making plots. It is based on ```matplotlib``` but offers more functions speicialized for statistical visualization. Also most people agree that ```seaborn``` looks more legit.\n",
        "\n",
        "Don\u0027t forget that you we will also give **2 points** for nice coding style!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Assignment 0: Peer review for sheet 01 [3 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Beginning this week you will have to make a peer review of the other groups\u0027 solutions. Each group reviews the solutions of two other groups and give points according to the given point distribution considering the correctness of the solution. For this reviews the tutors will give you up to 3 points each week.\n",
        "\n",
        "| * |Group 1|Group 2|Group 3|Group 4|Group 5|Group 6|Group 7|Group 8|Group 9|Group 10|Group 11|\n",
        "| ------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ------ | ------ |\n",
        "| check solutions of group: | 10, 7 | 4, 9  | 1, 4  | 11, 1 | 8, 11 | 5, 3  | 9, 10 | 6, 5  | 3, 2  | 2, 8   | 7, 6   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "You should open an issue in repositories of groups you have to check. The title of the issue should be your group name (e.g.\"Group 1\"). Comments on what was good and bad, how much points they get etc.  \n",
        "Refer to https://guides.github.com/features/issues/ to learn more about issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Assignment 1: Dataframes [4 pts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "```matplotlib``` and ```seaborn``` should already be installed in your environment. If not please run:\n",
        "```sh\n",
        "pip install seaborn\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### a) Importing a csv file [2 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Import the csv files of all subjects into one dataframe. Make sure that each row has a unique index. You might want to take a look at what ***pandas.concat*** does.\u003cbr\u003e\n",
        "Extra fun: Display the output of the dataframe using the ***pandas.set_option*** function to display the data in a well-arranged way. Play a little bit around with the settings that you are allowed to change.\u003cbr\u003e\n",
        "Save ```df_concatenated```.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "import os\nfrom pathlib import Path\n\n# Use the new, object-orientated Python paths rather than the old modules\n# By this, we have both a convenient interface and no struggles with separators\nPATH \u003d Path.cwd() / \"Data\"\n\n# Read all the experiments from the available CSV files and concatenate them.\n# In oder of getting not n time indeces from 0-99, we reset the indices by ignore_index.\nexperiments \u003d [pd.read_csv(file) for file in PATH.glob(\u0027*.csv\u0027)]\ndf_concatenated \u003d pd.concat(experiments, ignore_index\u003dTrue)\n\n# Before showing an overview of the data, we optimize the formatting.\n# We justify the headers to the right and limit the maximal about of printed rows further.\npd.set_option(\u0027colheader_justify\u0027, \u0027right\u0027)\npd.set_option(\u0027display.max_rows\u0027, 40)\ndf_concatenated\n\n# In the nex step, we save the concatenated dataframe.\n# Therefore, we create the folder if it does not exist and (over-)write the CSV file.\nDATAPATH \u003d Path.cwd() / \u0027Processed\u0027 / \u0027data_concatenated.csv\u0027\nDATAPATH.parent.mkdir(exist_ok\u003dTrue)\nwith DATAPATH.open(mode\u003d\u0027w\u0027, newline\u003d\u0027\u0027) as file:\n    df_concatenated.to_csv(file)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### b) Working with dataframes [2 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "- Add a column called \"congruence\" to ```df_concatenated```. The column should have a value *True* if \"StimulusType\" and \"reponse\" matches. Otherwise the column should have a value *False*.\n",
        "\n",
        "- Create a new dataframe which has \"SubjectID\",\"StiumulusType\",\"RT\" and \"congruence\" as a column. For each combination of \"SubjectID\" and \"StimulusType\" (e.g. \"7001\" and \"0\") compute the average RT and congruence level.\n",
        "\n",
        "- When computing the average RT, omit all reaction times which are 0 as these will manipulate the mean.\n",
        "\n",
        "- Rename \"congruence\" as \"accuracy\" and save the dataframe as a csv file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# add a column \"congruence\"\n",
        "# TODO\n",
        "\n",
        "# create a new dataframe with averaged data\n",
        "df_concatenated_avg \u003d # TODO\n",
        "\n",
        "# save averaged dataframe\n",
        "DATAPATH \u003d os.getcwd() + \u0027/Processed/data_concatenated_averaged.csv\u0027\n",
        "# TODO\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Assignment 2: Statistical plotting [6 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### a) Boxplot and Violinplot [2 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Plot the RT of each trial for all subjects as a stripplot and a boxplot on top of each other. Do the same with a striplot and a violinplot. Plot go trials as green dots and no-go trails as red dots. Reminder: don\u0027t forget to mask the data where RT\u003d0. Make sure that the legends are informative (Don\u0027t display duplicated legends)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# read data\n",
        "data_concat \u003d pd.read_csv(os.getcwd() + \"/Processed/data_concatenated.csv\")\n",
        "\n",
        "# create two axes\n",
        "fig, axes \u003d plt.subplots(nrows\u003d1,ncols\u003d2)\n",
        "\n",
        "# first subplot with stripplot and boxplot\n",
        "# TODO \n",
        "\n",
        "# second subplot with stripplot and violinplot\n",
        "# TODO\n",
        "\n",
        "# handling legends\n",
        "# TODO\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### b) Violinplot combining all data of all groups [3 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "- Make a dataframe consisting of all data across groups. You already did this in 1.a). At the end this dataframe you should have 8 * 11 * 100 rows.\n",
        "\n",
        "- Every group has used their ID convention. Make sure that every data point follows this SubjectID system: group number + \"00\" + subject number.  \n",
        "e.g) 3002 for the second subject of the third group.\n",
        "\n",
        "- Compute average RT and accuaracy for each subject in the big dataframe you just created. You already did this in 1.b). At the end this dataframe will have 8 * 11 rows.\n",
        "\n",
        "- On the first column plot average RT and accuracy for 8 subjects from your group\u0027s data. Use violinplot and split go/no-go conditions.\n",
        "\n",
        "- On the second column plot average RT and accuracy for 80 subjects from all data. Use violinplot and split go/no-go conditions.\n",
        "\n",
        "- Do you see any difference between the first column and the second column? What does this tell us about the central limit theorem (CLT) ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# again create a concatenated dataframe over all (averaged) groups.\n",
        "# Don\u0027t forget to modify the Subject ID\n",
        "# TODO\n",
        "\n",
        "# Now it\u0027s time to plot your results\n",
        "figs, axes \u003d plt.subplots(nrows\u003d2, ncols\u003d2, sharey\u003d\"row\")\n",
        "\n",
        "# violin plot for your group\u0027s data\n",
        "# TODO\n",
        "\n",
        "# violin plot of all group\u0027s data\n",
        "# TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Compare two datasets and relate it with CLT. Write your opinion here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### c) Scatterplot [1 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Make a scatterplot comparing RT and accuracy. Do you see some correlation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "pycharm-70970a36",
      "language": "python",
      "display_name": "PyCharm (week-4-acc_2)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}