{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Osnabrück University - A\u0026C: Computational Cognition (Summer Term 2019)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Exercise Sheet 02: Basic statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This week\u0027s sheet should be solved and handed in at 14:00 at **Tuesday, April 30, 2019**. If you need help (and Google and other resources were not enough), feel free to contact your tutors. Please push your results to your Github group folder.\n",
        "\n",
        "In this exercise sheet you will have to work with ```pandas``` and ```seaborn```. ```pandas``` is one of the most preferred and widely used tools in data processing. What’s cool about ```pandas``` is that it takes data (like a CSV or TSV file, or a SQL database) and creates a Python object with rows and columns called \u0027data frame\u0027 that looks very similar to tables in a statistical software (think Excel or SPSS for example). ```pandas``` makes data processing a lot easier in comparison to working with lists and/or dictionaries through for-loops or list comprehension.  \n",
        "```seaborn``` is a library for making plots. It is based on ```matplotlib``` but offers more functions speicialized for statistical visualization. Also most people agree that ```seaborn``` looks more legit.\n",
        "\n",
        "Don\u0027t forget that you we will also give **2 points** for nice coding style!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Assignment 0: Peer review for sheet 01 [3 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Beginning this week you will have to make a peer review of the other groups\u0027 solutions. Each group reviews the solutions of two other groups and give points according to the given point distribution considering the correctness of the solution. For this reviews the tutors will give you up to 3 points each week.\n",
        "\n",
        "| * |Group 1|Group 2|Group 3|Group 4|Group 5|Group 6|Group 7|Group 8|Group 9|Group 10|Group 11|\n",
        "| ------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ------ | ------ |\n",
        "| check solutions of group: | 10, 7 | 4, 9  | 1, 4  | 11, 1 | 8, 11 | 5, 3  | 9, 10 | 6, 5  | 3, 2  | 2, 8   | 7, 6   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "You should open an issue in repositories of groups you have to check. The title of the issue should be your group name (e.g.\"Group 1\"). Comments on what was good and bad, how much points they get etc.  \n",
        "Refer to https://guides.github.com/features/issues/ to learn more about issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Assignment 1: Dataframes [4 pts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "```matplotlib``` and ```seaborn``` should already be installed in your environment. If not please run:\n",
        "```sh\n",
        "pip install seaborn\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### a) Importing a csv file [2 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Import the csv files of all subjects into one dataframe. Make sure that each row has a unique index. You might want to take a look at what ***pandas.concat*** does.\u003cbr\u003e\n",
        "Extra fun: Display the output of the dataframe using the ***pandas.set_option*** function to display the data in a well-arranged way. Play a little bit around with the settings that you are allowed to change.\u003cbr\u003e\n",
        "Save ```df_concatenated```.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "     SubjectID  StimulusType  response   RT\n0          111             1         0    0\n1          111             0         0    0\n2          111             1         1  585\n3          111             1         1  615\n4          111             1         1  402\n5          111             0         0    0\n6          111             1         1  719\n7          111             1         1  551\n8          111             1         1  482\n9          111             1         1  483\n10         111             0         0    0\n11         111             1         1  368\n12         111             1         1  446\n13         111             1         1  497\n14         111             1         1  530\n15         111             1         1  633\n16         111             1         1  448\n17         111             1         1  435\n18         111             1         1  385\n19         111             1         1  369\n..         ...           ...       ...  ...\n780        313             0         0    0\n781        313             1         1  451\n782        313             1         1  323\n783        313             1         1  290\n784        313             1         1  322\n785        313             0         0    0\n786        313             1         1  499\n787        313             1         1  323\n788        313             1         1  289\n789        313             1         1  291\n790        313             1         1  273\n791        313             0         0    0\n792        313             1         1  352\n793        313             1         1  323\n794        313             0         0    0\n795        313             1         1  306\n796        313             1         1  306\n797        313             1         1  321\n798        313             1         1  289\n799        313             1         1  355\n\n[800 rows x 4 columns]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import os\nfrom pathlib import Path\n\n# Use the new, object-orientated Python paths rather than the old modules\n# By this, we have both a convenient interface and no struggles with separators\nPATH \u003d Path.cwd() / \"Data\"\n\n# Read all the experiments from the available CSV files and concatenate them.\n# In oder of getting not n time indeces from 0-99, we reset the indices by ignore_index.\nexperiments \u003d [pd.read_csv(file) for file in PATH.glob(\u0027*.csv\u0027)]\ndf_concatenated \u003d pd.concat(experiments, ignore_index\u003dTrue)\n\n# Before showing an overview of the data, we optimize the formatting.\n# We justify the headers to the right and limit the maximal about of printed rows further.\npd.set_option(\u0027colheader_justify\u0027, \u0027right\u0027)\npd.set_option(\u0027display.max_rows\u0027, 40)\nprint(df_concatenated)\n\n# In the nex step, we save the concatenated dataframe.\n# Therefore, we create the folder if it does not exist and (over-)write the CSV file.\nDATAPATH \u003d Path.cwd() / \u0027Processed\u0027 / \u0027data_concatenated.csv\u0027\nDATAPATH.parent.mkdir(exist_ok\u003dTrue)\nwith DATAPATH.open(mode\u003d\u0027w\u0027, newline\u003d\u0027\u0027) as file:\n    df_concatenated.to_csv(file)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### b) Working with dataframes [2 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "- Add a column called \"congruence\" to ```df_concatenated```. The column should have a value *True* if \"StimulusType\" and \"reponse\" matches. Otherwise the column should have a value *False*.\n",
        "\n",
        "- Create a new dataframe which has \"SubjectID\",\"StiumulusType\",\"RT\" and \"congruence\" as a column. For each combination of \"SubjectID\" and \"StimulusType\" (e.g. \"7001\" and \"0\") compute the average RT and congruence level.\n",
        "\n",
        "- When computing the average RT, omit all reaction times which are 0 as these will manipulate the mean.\n",
        "\n",
        "- Rename \"congruence\" as \"accuracy\" and save the dataframe as a csv file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": false,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "# We add a column \"congruence\".\n# The assign function applies an anonymous function to all rows and save the result by the name of the argument\ndf_concatenated \u003d df_concatenated.assign(congruence\u003dlambda row: row.StimulusType \u003d\u003d row.response)\n\n# We create a new dataframe with averaged data\n# Pandas works a bit like SQL:\n#   1. First we filter for invalid reaction times ...\n#   2. ... than we group the data by our columns of interest ...\n#   3. ... and calculate the average.\ndf_concatenated_avg \u003d df_concatenated[df_concatenated.RT \u003e 0]\\\n    .groupby([\u0027SubjectID\u0027, \u0027StimulusType\u0027])\\\n    .mean()\n\n# We rename \"congruence\" to \"accuracy\" inplace.\ndf_concatenated_avg.rename(index\u003dstr, columns\u003d{\"congruence\": \"accuracy\"}, inplace\u003dTrue)\n\n# Afterwards, we save the result into the already created folder.\nDATAPATH \u003d Path.cwd() / \u0027Processed\u0027 / \u0027data_concatenated_averaged.csv\u0027\nwith DATAPATH.open(mode\u003d\u0027w\u0027, newline\u003d\u0027\u0027) as file:\n    df_concatenated_avg.to_csv(file)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Assignment 2: Statistical plotting [6 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### a) Boxplot and Violinplot [2 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Plot the RT of each trial for all subjects as a stripplot and a boxplot on top of each other. Do the same with a striplot and a violinplot. Plot go trials as green dots and no-go trails as red dots. Reminder: don\u0027t forget to mask the data where RT\u003d0. Make sure that the legends are informative (Don\u0027t display duplicated legends)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# read data\n",
        "data_concat \u003d pd.read_csv(os.getcwd() + \"/Processed/data_concatenated.csv\")\n",
        "\n",
        "# create two axes\n",
        "fig, axes \u003d plt.subplots(nrows\u003d1,ncols\u003d2)\n",
        "\n",
        "# first subplot with stripplot and boxplot\n",
        "# TODO \n",
        "\n",
        "# second subplot with stripplot and violinplot\n",
        "# TODO\n",
        "\n",
        "# handling legends\n",
        "# TODO\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### b) Violinplot combining all data of all groups [3 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "- Make a dataframe consisting of all data across groups. You already did this in 1.a). At the end this dataframe you should have 8 * 11 * 100 rows.\n",
        "\n",
        "- Every group has used their ID convention. Make sure that every data point follows this SubjectID system: group number + \"00\" + subject number.  \n",
        "e.g) 3002 for the second subject of the third group.\n",
        "\n",
        "- Compute average RT and accuaracy for each subject in the big dataframe you just created. You already did this in 1.b). At the end this dataframe will have 8 * 11 rows.\n",
        "\n",
        "- On the first column plot average RT and accuracy for 8 subjects from your group\u0027s data. Use violinplot and split go/no-go conditions.\n",
        "\n",
        "- On the second column plot average RT and accuracy for 80 subjects from all data. Use violinplot and split go/no-go conditions.\n",
        "\n",
        "- Do you see any difference between the first column and the second column? What does this tell us about the central limit theorem (CLT) ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# again create a concatenated dataframe over all (averaged) groups.\n",
        "# Don\u0027t forget to modify the Subject ID\n",
        "# TODO\n",
        "\n",
        "# Now it\u0027s time to plot your results\n",
        "figs, axes \u003d plt.subplots(nrows\u003d2, ncols\u003d2, sharey\u003d\"row\")\n",
        "\n",
        "# violin plot for your group\u0027s data\n",
        "# TODO\n",
        "\n",
        "# violin plot of all group\u0027s data\n",
        "# TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Compare two datasets and relate it with CLT. Write your opinion here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### c) Scatterplot [1 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Make a scatterplot comparing RT and accuracy. Do you see some correlation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "pycharm-70970a36",
      "language": "python",
      "display_name": "PyCharm (week-4-acc_2)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}